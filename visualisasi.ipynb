{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impor library yang diperlukan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Impor dari TensorFlow dan Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model = tf.keras.models.load_model('./saved_model/')\n",
    "model = load_model('lbpvgg10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'haarcascade_frontalface_default.xml'\n",
    "font_scale = 1.5\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "rectangle_bgr = (255,255,255)\n",
    "\n",
    "img = np.zeros((500,500))\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "(text_width, text_height) = cv2.getTextSize(text, font, fontScale=font_scale, thickness=1)[0]\n",
    "\n",
    "text_offset_x = 10\n",
    "text_offset_y = img.shape[0] -25\n",
    "\n",
    "box_coords = ((text_offset_x, text_offset_y), (text_offset_x+text_width+2, text_offset_y-text_height-2))\n",
    "\n",
    "cv2.rectangle(img, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "  \n",
    "org = (50, 50)\n",
    "  \n",
    "fontScale = 1\n",
    "   \n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "cv2.putText(img, 'OpenCV', org, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "face_roi = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not vid.isOpened():\n",
    "#     print(\"Error: Kamera tidak dapat diakses\")\n",
    "#     exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daftar emosi\n",
    "emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprised\"]\n",
    "base_dir = 'ss'\n",
    "\n",
    "# Hapus dan buat ulang folder untuk setiap emosi\n",
    "for emotion in emotions:\n",
    "    emotion_dir = os.path.join(base_dir, emotion)\n",
    "    if os.path.exists(emotion_dir):\n",
    "        shutil.rmtree(emotion_dir)  # Menghapus folder beserta isinya\n",
    "    os.makedirs(emotion_dir)  # Membuat folder yang baru\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "if not vid.isOpened():\n",
    "    print(\"Error: Kamera tidak dapat diakses\")\n",
    "    exit()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while(True):\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        print(\"Gagal mendapatkan frame.\")\n",
    "        break\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "    face_roi = None\n",
    "    \n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Menggambar persegi pada frame asli\n",
    "        face_roi = roi_gray  # Menggunakan roi_gray untuk analisis\n",
    "\n",
    "    if face_roi is not None:\n",
    "        image = cv2.resize(face_roi, (100, 100))\n",
    "        X = np.expand_dims(image, axis=0)\n",
    "        X = X / 255\n",
    "        images = np.vstack([X])\n",
    "\n",
    "        val=model.predict(images)\n",
    "\n",
    "        prediction_value = np.argmax(val[0])\n",
    "\n",
    "        #Interpretation der Prediction:\n",
    "        if(prediction_value == 0):\n",
    "            status = \"Angry\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 1):\n",
    "            status = \"Disgust\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 2):\n",
    "            status = \"Fear\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 3):\n",
    "            status = \"Happy\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 4):\n",
    "            status = \"Neutral\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 5):\n",
    "            status = \"Sad\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 6):\n",
    "            status = \"Suprised\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        \n",
    "\n",
    "        # Mapping dari prediction_value ke status emosi\n",
    "        emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprised\"]\n",
    "        status = emotions[prediction_value] if prediction_value < len(emotions) else \"Unknown\"\n",
    "        \n",
    "        cv2.putText(gray, status, (100, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.rectangle(gray, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "        # Membuat folder untuk setiap emosi jika belum ada\n",
    "        emotion_dir = f\"ss/{status}\"\n",
    "        if not os.path.exists(emotion_dir):\n",
    "            os.makedirs(emotion_dir)\n",
    "\n",
    "        cv2.imshow('Face Emotion Recognition', gray)\n",
    "\n",
    "    if time.time() - start_time >= 10:\n",
    "        # Menambahkan teks status ke frame asli\n",
    "        cv2.putText(frame, status, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        # Menyimpan frame dengan status ke dalam folder berdasarkan emosi\n",
    "        emotion_folder = os.path.join(base_dir, status)\n",
    "        filename = os.path.join(emotion_folder, f\"frame_{int(time.time())}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Frame saved in '{status}' folder: {filename}\")\n",
    "        start_time = time.time()\n",
    "            \n",
    "    cv2.imshow('Face Emotion Recognition', frame)  # Menampilkan frame dengan bounding box dan status\n",
    "\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame saved in 'Happy' folder: ss\\Happy\\frame_1709651091.jpg\n",
      "Frame saved in 'Surprised' folder: ss\\Surprised\\frame_1709651091.jpg\n",
      "Frame saved in 'Surprised' folder: ss\\Surprised\\frame_1709651092.jpg\n",
      "Frame saved in 'Surprised' folder: ss\\Surprised\\frame_1709651092.jpg\n",
      "Frame saved in 'Surprised' folder: ss\\Surprised\\frame_1709651092.jpg\n",
      "Frame saved in 'Surprised' folder: ss\\Surprised\\frame_1709651092.jpg\n",
      "Frame saved in 'Disgust' folder: ss\\Disgust\\frame_1709651092.jpg\n",
      "Frame saved in 'Angry' folder: ss\\Angry\\frame_1709651093.jpg\n",
      "Frame saved in 'Happy' folder: ss\\Happy\\frame_1709651093.jpg\n",
      "Frame saved in 'Neutral' folder: ss\\Neutral\\frame_1709651093.jpg\n",
      "Frame saved in 'Happy' folder: ss\\Happy\\frame_1709651093.jpg\n",
      "Frame saved in 'Happy' folder: ss\\Happy\\frame_1709651094.jpg\n",
      "Frame saved in 'Angry' folder: ss\\Angry\\frame_1709651094.jpg\n",
      "Frame saved in 'Neutral' folder: ss\\Neutral\\frame_1709651094.jpg\n",
      "Frame saved in 'Sad' folder: ss\\Sad\\frame_1709651094.jpg\n",
      "Frame saved in 'Disgust' folder: ss\\Disgust\\frame_1709651095.jpg\n",
      "Frame saved in 'Sad' folder: ss\\Sad\\frame_1709651095.jpg\n",
      "Frame saved in 'Neutral' folder: ss\\Neutral\\frame_1709651095.jpg\n",
      "Frame saved in 'Disgust' folder: ss\\Disgust\\frame_1709651095.jpg\n",
      "Frame saved in 'Sad' folder: ss\\Sad\\frame_1709651095.jpg\n",
      "Frame saved in 'Happy' folder: ss\\Happy\\frame_1709651096.jpg\n",
      "Frame saved in 'Surprised' folder: ss\\Surprised\\frame_1709651096.jpg\n",
      "Frame saved in 'Happy' folder: ss\\Happy\\frame_1709651096.jpg\n",
      "Frame saved in 'Neutral' folder: ss\\Neutral\\frame_1709651096.jpg\n",
      "Frame saved in 'Neutral' folder: ss\\Neutral\\frame_1709651096.jpg\n",
      "Frame saved in 'Happy' folder: ss\\Happy\\frame_1709651097.jpg\n",
      "Frame saved in 'Happy' folder: ss\\Happy\\frame_1709651097.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Daftar emosi\n",
    "emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprised\"]\n",
    "base_dir = 'ss'\n",
    "\n",
    "# Hapus dan buat ulang folder untuk setiap emosi\n",
    "for emotion in emotions:\n",
    "    emotion_dir = os.path.join(base_dir, emotion)\n",
    "    if os.path.exists(emotion_dir):\n",
    "        shutil.rmtree(emotion_dir)  # Menghapus folder beserta isinya\n",
    "    os.makedirs(emotion_dir)  # Membuat folder yang baru\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "if not vid.isOpened():\n",
    "    print(\"Error: Kamera tidak dapat diakses\")\n",
    "    exit()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while(True):\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        print(\"Gagal mendapatkan frame.\")\n",
    "        break\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
    "    face_roi = None\n",
    "    \n",
    "    for x, y, w, h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Menggambar persegi pada frame asli\n",
    "        face_roi = roi_gray  # Menggunakan roi_gray untuk analisis\n",
    "\n",
    "    if face_roi is not None:\n",
    "        image = cv2.resize(face_roi, (100, 100))\n",
    "        X = np.expand_dims(image, axis=0)\n",
    "        X = X / 255\n",
    "        images = np.vstack([X])\n",
    "\n",
    "        # Menambahkan teks status ke frame asli\n",
    "        cv2.putText(frame, status, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # Menyimpan frame dengan status ke dalam folder berdasarkan emosi\n",
    "        emotion_folder = os.path.join(base_dir, status)\n",
    "        filename = os.path.join(emotion_folder, f\"frame_{int(time.time())}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Frame saved in '{status}' folder: {filename}\")\n",
    "\n",
    "    cv2.imshow('Face Emotion Recognition', frame)  # Menampilkan frame dengan bounding box dan status\n",
    "\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daftar emosi\n",
    "emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\", \"Surprised\"]\n",
    "base_dir = 'ss'\n",
    "\n",
    "# Hapus dan buat ulang folder untuk setiap emosi\n",
    "for emotion in emotions:\n",
    "    emotion_dir = os.path.join(base_dir, emotion)\n",
    "    if os.path.exists(emotion_dir):\n",
    "        shutil.rmtree(emotion_dir)  # Menghapus folder beserta isinya\n",
    "    os.makedirs(emotion_dir)  # Membuat folder yang baru\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Ermittlung aller im Bild enthaltenen Gesichter\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1,4)\n",
    "    \n",
    "    #Iteration über jedes Bild und entsprechende Anpassung der Bildmaße und Bildwerte\n",
    "    for x,y,w,h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = gray[y:y+h, x:x+w]\n",
    "        cv2.rectangle(gray, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "        face_roi = roi_color\n",
    "        \n",
    "    if(face_roi is not None):\n",
    "        image = cv2.resize(face_roi, (100,100))\n",
    "        X = np.expand_dims(image, axis = 0)\n",
    "        X = X/255\n",
    "        images = np.vstack([X])\n",
    "\n",
    "        #Jetzt können wir mit unserem Modell eine Vorhersage treffen:\n",
    "        val=my_model.predict(images)\n",
    "\n",
    "        prediction_value = np.argmax(val[0])\n",
    "\n",
    "        #Interpretation der Prediction:\n",
    "        if(prediction_value == 0):\n",
    "            status = \"Angry\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 1):\n",
    "            status = \"Disgust\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 2):\n",
    "            status = \"Fear\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 3):\n",
    "            status = \"Happy\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 4):\n",
    "            status = \"Neutral\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 5):\n",
    "            status = \"Sad\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 6):\n",
    "            status = \"Suprised\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "\n",
    "    cv2.imshow('Face Emotion Recognition', gray)\n",
    "\n",
    "    if time.time() - start_time >= 10:\n",
    "        # Menambahkan teks status ke frame asli\n",
    "        cv2.putText(frame, status, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        # Menyimpan frame dengan status ke dalam folder berdasarkan emosi\n",
    "        emotion_folder = os.path.join(base_dir, status)\n",
    "        filename = os.path.join(emotion_folder, f\"frame_{int(time.time())}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Frame saved in '{status}' folder: {filename}\")\n",
    "        start_time = time.time()\n",
    "            \n",
    "    cv2.imshow('Face Emotion Recognition', frame)  # Menampilkan frame dengan bounding box dan status\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Frame saved in 'Sad' folder: ss\\Sad\\frame_Sad1709652289.jpg\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Frame saved in 'Angry' folder: ss\\Angry\\frame_Angry1709652299.jpg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "# Hapus dan buat ulang folder untuk setiap emosi\n",
    "for emotion in emotions:\n",
    "    emotion_dir = os.path.join(base_dir, emotion)\n",
    "    if os.path.exists(emotion_dir):\n",
    "        shutil.rmtree(emotion_dir)  # Menghapus folder beserta isinya\n",
    "    os.makedirs(emotion_dir)  # Membuat folder yang baru\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Ermittlung aller im Bild enthaltenen Gesichter\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.1,4)\n",
    "    \n",
    "    #Iteration über jedes Bild und entsprechende Anpassung der Bildmaße und Bildwerte\n",
    "    for x,y,w,h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = gray[y:y+h, x:x+w]\n",
    "        cv2.rectangle(gray, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "        face_roi = roi_color\n",
    "    if(face_roi is not None):\n",
    "        image = cv2.resize(face_roi, (100,100))\n",
    "        X = np.expand_dims(image, axis = 0)\n",
    "        X = X/255\n",
    "        images = np.vstack([X])\n",
    "\n",
    "        #Jetzt können wir mit unserem Modell eine Vorhersage treffen:\n",
    "        val=my_model.predict(images)\n",
    "\n",
    "        prediction_value = np.argmax(val[0])\n",
    "\n",
    "        #Interpretation der Prediction:\n",
    "        if(prediction_value == 0):\n",
    "            status = \"Angry\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 1):\n",
    "            status = \"Disgust\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 2):\n",
    "            status = \"Fear\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 3):\n",
    "            status = \"Happy\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 4):\n",
    "            status = \"Neutral\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 5):\n",
    "            status = \"Sad\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "        elif (prediction_value == 6):\n",
    "            status = \"Suprised\"\n",
    "            x1,y1,w1,h1 = 0,0,175,75\n",
    "            cv2.rectangle(gray, (x1,x1), (x1+w1,y1+h1), (0,0,0), -1)\n",
    "            cv2.putText(gray, status, (x1+int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(gray, status,(100,150), font, 3,(0,0,255), 2, cv2.LINE_4)\n",
    "            cv2.rectangle(gray, (x,y), (x+w, y+h), (0,0,255))\n",
    "\n",
    "\n",
    "    cv2.imshow('Face Emotion Recognition', gray)\n",
    "\n",
    "    if time.time() - start_time >= 10:\n",
    "        # Menambahkan teks status ke frame asli\n",
    "        cv2.putText(frame, status, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        # Menyimpan frame dengan status ke dalam folder berdasarkan emosi\n",
    "        emotion_folder = os.path.join(base_dir, status)\n",
    "        filename = os.path.join(emotion_folder, f\"frame_{str(status)}{int(time.time())}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Frame saved in '{status}' folder: {filename}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(status))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
